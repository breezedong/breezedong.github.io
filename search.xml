<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[提高效率方法]]></title>
      <url>http://yoursite.com/2016/06/06/%E6%8F%90%E9%AB%98%E6%95%88%E7%8E%87%E6%96%B9%E6%B3%95/</url>
      <content type="html"><![CDATA[<h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>最近一篇名为<a href="http://blog.jobbole.com/101608/" target="_blank" rel="external">程序员提高效率的一些建议</a>的博文写的非常好，正好适合环境、精神和方法三个方面都一团糟的我，窃以为这些建议不仅仅适用于程序员，而且适用于大多数人，遂将其整理了一下，主要的思想脉络如下图所示：<br><img src="https://git.oschina.net/breezedong/figure_bed/raw/master/efficiency_improvement.png" alt="efficiency_improvement"></p>
<p>其主要从以下三个方面来提高效率：</p>
<ul>
<li><strong>环境</strong>，所谓孟母三迁，环境对一个人的影响力还是很大的，简洁、舒适的环境对效率来说，第一重要。</li>
<li><strong>精神</strong>，健康合理的心理状态是不可或缺的，拖延症，焦虑感，合理时间安排都是精神状态的重要因素。</li>
<li><strong>方法</strong>，有计划做事，团队合作，对效率提升效果显著。</li>
</ul>
<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><h2 id="避免打扰"><a href="#避免打扰" class="headerlink" title="避免打扰"></a>避免打扰</h2><p>电话、短信、邮件等等东西，会不断的将你的时间切成碎片。<strong>当你完成复杂任务的时候，这种不断的打扰会让你的思维迟缓，而你从打断状态返回任务状态所需要的时间和精力成本会很大</strong>。<br>所以，我们需要做到：</p>
<ul>
<li>手机免打扰状态，统一在休息时间查收信息。</li>
<li>桌面关闭社交软件，关闭无关网页。</li>
<li>会议安排在最开始，精简。</li>
</ul>
<h2 id="精通工具"><a href="#精通工具" class="headerlink" title="精通工具"></a>精通工具</h2><blockquote>
<p>工欲善其事必先利其器。</p>
</blockquote>
<p>形成自己的工具链，无论是项目管理还是团队协作，还是专业编程软件。对于常用的软件，能用快捷键，尽量不要使用鼠标。让自己的行动跟上思维。</p>
<h2 id="照顾身体"><a href="#照顾身体" class="headerlink" title="照顾身体"></a>照顾身体</h2><blockquote>
<p>身体是革命的本钱。</p>
</blockquote>
<p>以自己身体为代价的拼命行为，得不偿失。所以，我们需要有良好的习惯。</p>
<ul>
<li>多喝水。每天定量需要喝多少水。</li>
<li>定期运动。每周进行周期性的运动锻炼，有助于活跃思维，保持身体机能健康。</li>
<li>饮食清淡。尽量少吃辛辣咸的食物，有助于维持血压和血脂。</li>
</ul>
<h2 id="工位精简"><a href="#工位精简" class="headerlink" title="工位精简"></a>工位精简</h2><blockquote>
<p>搜寻有用物品时，在没用的物品身上浪费的时间多于找到有用的物品本身。所以，尽量精简你的额工位和你的手机，电脑。</p>
</blockquote>
<p>定期整理工位，手机和PC。将常用的物品和软件，永远放在最显眼的地方，没有用的物品，尽量清理掉。</p>
<h1 id="精神"><a href="#精神" class="headerlink" title="精神"></a>精神</h1><p>良好的精神状态，是工作效率的重要保障。犹如运动员保持良好的竞技状态一样。</p>
<h2 id="定时休息"><a href="#定时休息" class="headerlink" title="定时休息"></a>定时休息</h2><p>人非机器，不是花在工作上的时间越多，收获就越多。因为注意力的保持是具有周期性的。这里推荐腾讯内部使用的番茄时间工作法，当然也可以设置自己的工作单位周期。我的时间周期为45/15，即工作45分钟，休息15分钟。</p>
<h2 id="焦虑与拖延"><a href="#焦虑与拖延" class="headerlink" title="焦虑与拖延"></a>焦虑与拖延</h2><p>焦虑是学习最大的敌人。<br>焦虑和拖延往往是并发的。人在压力大，任务重要的时候，容易产生焦虑心理。焦虑后，就容易将任务拖延。<br>当我们面对复杂困难任务时，庞大的压力使人产生焦虑，焦虑让人产生逃避心理，宁愿去刷微博，facebook，新闻等讯息，也不愿意面对任务，从而产生拖延症。针对焦虑和拖延，我们采用以下两种办法进行有效的处理。</p>
<ul>
<li><a href="http://www.zhihu.com/question/20153152" target="_blank" rel="external">冥想</a>，正念练习，数呼吸数，坚持10-15分钟。动作要领：脊椎坐直，肩膀放松，从一到十，往复循环。最好的方法是把注意力放在人中一带的皮肤处，觉知这地方经过的入息、出息，只是知道入出息，而不要太注意皮肤的触觉、或呼吸的其他特质。</li>
<li><a href="http://www.mifengtd.cn/articles/structured-procrastination.html" target="_blank" rel="external">结构化拖延法</a>，斯坦福哲学教授John Perry使用这个策略能把拖沓成性的人变成高效人士。<strong>结构化拖延法核心思想：将所有任务按照优先级列成list，并且不断更新。在最顶端任务的压力下，其完成其他任务。</strong></li>
</ul>
<p>拖延的人往往误入歧途。他们想要减少任务，觉得如果只有很少事情可做的话，他们会立即抖擞精神，把事情搞定。这其实和拖沓之人的本性相反，反倒毁掉了他们更重要的去做事的驱动力。列表上任务越少就越显得重要，只有一个方法可以逃避这些任务，那就是什么事情都不做。这样他们就成了扶不上墙的烂泥，远非一个高效人士。</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>想要提高效率，好的方法必不可少。</p>
<h2 id="计划"><a href="#计划" class="headerlink" title="计划"></a>计划</h2><p>制定清晰的计划</p>
<h2 id="团队合作"><a href="#团队合作" class="headerlink" title="团队合作"></a>团队合作</h2><p>复杂的工作，独立完成会缺少效率。有其他人在的情况下，有如下优点：</p>
<ul>
<li>头脑风暴，集中精神思考问题</li>
<li>设置任务时间节点，相互监督情况下，容易转化压力为动力</li>
<li>复杂任务分解，相互引导过程中，会加快问题的解决。<br>在团队合作工具的选择上，我再<a href="https://asana.com/" target="_blank" rel="external">asana</a>与<a href="https://www.teambition.com" target="_blank" rel="external">teambition</a>之间选择了后者。虽然asana是团队协作工具的鼻祖，而且功能目前最为丰富；但是teambition为国内软件中最为好用，而且考虑到语言成本和网络强等因素，我选择后者。其实这个道理适用于所有的工具选择问题：工具本身基本功能都差不多，不必拘泥于哪一款，选择学习成本最低，适合自己的就行，用好最基本的，再选择换到更高级的工具。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>每天在冥想之余，花一点时间总结自己的工作及效率，看看有无改善之处。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[计算机网络回顾笔记]]></title>
      <url>http://yoursite.com/2016/06/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9B%9E%E9%A1%BE%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h1><p>计算机科学，离不开算法的设计，其作为人类智慧的结晶，以计算机语言的形式展现出来，是整个计算机学科和人工智能的基础。最近重新温习了一遍本科阶段的一本计算机网络书籍，带着欣赏算法的眼光，来重新梳理了一遍此课程的脉络。<br>计算机网络是一门讲述计算机之间如何通信的课程。<br>其主要的脉络：</p>
<ul>
<li>物理构成：网络外围的主机和网络核心的路由器和交换机</li>
<li>逻辑结构：五层结构，物理层，数据链路层，网络层，运输层，应用层</li>
</ul>
<p>整个计算机通信网络是依靠分组交换的方式，在计算机之间传输报文。物理层负责提供电流通道，信息传输；数据链路层负责将电流通道从逻辑上进行整理，统一管理通道；网络层负责管理报文运输的路由，准确性；运输层负责管理报文运输过程中的质量和效率；应用层负责管理报文中实际应用数据的组织形式。</p>
<p>如果将计算机网络比做交通运输网络，则物理层就是提供车辆行驶的路；数据链路层就是规划的路，如立交桥，车道等；网络层就是车辆运输的起始和终点管理；运输层就是交通工具，轿车，货车等；应用层就是运输的物质，石头，砖块，家禽等等。<br>当然，有一些比喻不恰当的地方。<br>如下图所示：</p>
<p><img src="https://git.oschina.net/breezedong/figure_bed/raw/master/computer_network.png" alt="image"></p>
<h1 id="说说路由器与交换机"><a href="#说说路由器与交换机" class="headerlink" title="说说路由器与交换机"></a>说说路由器与交换机</h1><p>虽然平时在实验室一直接触到各种各样的路由器和交换机，但是还真没有弄明白它们的区别。<br>所谓交换机，工作在二层（数据链路层）的集线器或网桥，其将主机连接在一起，完成数据包的交换功能。<br>路由器，工作在三层（网络层）的路由设备，其完成主机之间寻址功能。<br>平时家用的小型路由器涵盖了四个交换口和路由器功能。而常见的三层交换机，也是包括了交换功能和路由功能。</p>
<h1 id="感悟"><a href="#感悟" class="headerlink" title="感悟"></a>感悟</h1><p>本科时候学习的方法真的很机械，学习TCP差错控制，就是去记忆它是怎么实现差错控制，殊不知，其真正的目的在于实现数据传输的准确性。<strong>本科阶段大多课程，继承了高中时期填鸭式的学习方法，大多只是机械的记忆一些方法技巧，而忽略了这些方法技巧的目的和意义。</strong>这样就好比将大量文件复制拷贝到了你的大脑存储中，但是你却没有形成对这些文件的索引，长久下去，他们会成为一种累赘。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Predicting Vulnerable Software Components via Text Mining]]></title>
      <url>http://yoursite.com/2016/06/01/Mining/</url>
      <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>文章于2014年10月份发表在IEEE TRANSACTIONS ON SOFTWARE ENGINEERING，一篇通过文本挖掘技术进行软件漏洞检测的论文。文章本身引用只有<a href="https://scholar.google.com/scholar?hl=zh-CN&amp;q=Predicting+Vulnerable+Software+Components+via+Text+Mining&amp;btnG=&amp;lr=" target="_blank" rel="external">14</a>，创新点也不是很新，但由于其期刊等级较高，而且文章数据处理分析较多，还是值得以后写作借鉴。</p>
<ul>
<li>出处：IEEE TRANSACTIONS ON SOFTWARE ENGINEERING, VOL. 40, NO. 10, OCTOBER 2014</li>
<li>作者：Riccardo Scandariato, James Walden, Aram Hovsepyan, and Wouter Joosen</li>
</ul>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="论文主要观点"><a href="#论文主要观点" class="headerlink" title="论文主要观点"></a>论文主要观点</h2><p>将Android app应用软件源代码视作文本，源代码中语句与词类比于文本中词，作为数据特征，使用朴素贝叶斯和随机森林的算法，构建软件源代码漏洞预测模型。</p>
<h2 id="成果"><a href="#成果" class="headerlink" title="成果"></a>成果</h2><ul>
<li>首次将文本挖掘相关方法应用于软件漏洞预测，直接使用源代码而非软件语义、开发者相关特征作为特征进行预测。</li>
<li>预测模型相对于当前的软件漏洞预测模型，具有更好的准确性和召回率。</li>
</ul>
<h1 id="方法模型"><a href="#方法模型" class="headerlink" title="方法模型"></a>方法模型</h1><h2 id="相关工作图"><a href="#相关工作图" class="headerlink" title="相关工作图"></a>相关工作图</h2><p>作者使用五个维度的信息来评价对比软件漏洞预测模型相关工作，如下图所示：<br><img src="https://git.oschina.net/breezedong/figure_bed/raw/master/vulnerability_prediction_models_related_work.jpg" alt="image"></p>
<h2 id="主要步骤"><a href="#主要步骤" class="headerlink" title="主要步骤"></a>主要步骤</h2><ul>
<li>样本选择selection of applications：<ul>
<li>source: the F-Droid repository (f-droid.org) </li>
<li>selection criteria:programming language, application size, and the number of<br>versions released</li>
</ul>
</li>
<li>漏洞数据构建construction of dataset：<ul>
<li>tool:HP Fortify SCA  scan the source code to present vulnerablity warnings of the applications</li>
<li>why:too few vulnerabilities(NVD<br>(nvd.nist.gov)) related to Android applications </li>
</ul>
</li>
<li>输入构建input：Each Java file is tokenized into a vector of terms</li>
<li>机器学习方法选择machine learning techniques:five, wellknown learning techniques are applied to the approache: Decision Trees, k-Nearest<br>Neighbor, Na€ ıve Bayes, Random Forest and support vector machine (SVM). Best results are obtained with <strong>NB and Random Forest</strong>.</li>
<li>实验设计experiments design:<ul>
<li>验证方法validation:10-fold cross-validation</li>
<li>experiment 1:built models with both Na€ ıve Bayes and Random Forest machine learning techniques based on the first version (v0) of each application.prove the method can be used to build high quality prediction models for Android applications.</li>
<li>experiment 2:built a prediction model based on the initial version (using all source files available in v0) and predicted all subsequent versions of that application (v1 andfollowing) prediction technique can forecast with excellent performance the vulnerable files of the future versions of an Android application</li>
<li>experiment 3：built 20 models using version v0 of each application. We then tested each model by predicting vulnerable files in the v0 versions of the other 19 applications.a single application can predict which software components are vulnerable in other applications</li>
</ul>
</li>
</ul>
<h1 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h1><ul>
<li>文本挖掘方法应用于软件缺陷检测</li>
<li>实验设计上，进行三个方向上的对比实验</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li>文章的实验部分数据对比写的不错，很简单的创意和想法，做出了三组实验</li>
</ul>
<h2 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h2><ul>
<li>创新点较为简单</li>
<li>数据对比牵强，数据集不同</li>
<li>期刊论文过于滞后，本文2014年10月发表，但是研究时间节点在2012年前后，以后尽量多看会议论文，期刊论文仅作为参考文献</li>
</ul>
<h2 id="我的想法"><a href="#我的想法" class="headerlink" title="我的想法"></a>我的想法</h2><ul>
<li>结合vccfinder论文</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[数据结构与算法]]></title>
      <url>http://yoursite.com/2016/05/29/data-algorithm/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<p>近日压力倍增，在图书馆自习，期望能够看更多的论文。休息期间找到一本算法的教材，从机器学习和人工智能的角度重温了一遍数据结构与算法。</p>
</blockquote>
<p>本科阶段曾学习过<strong>数据结构与算法</strong>这门课程，使用的是C语言实现的小绿书。依稀记得当时老师只是讲解了计算机程序中常见的数据结构，<strong>例如线性表，队列，栈等的存储方式以及增删查改的操作实现方法</strong>，并且给出了程序时间复杂度和空间复杂度的概念和分析方法。<br>很明确的一个概念：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">program = data + algorithm</span><br></pre></td></tr></table></figure>
<h1 id="数据结构算法与机器学习"><a href="#数据结构算法与机器学习" class="headerlink" title="数据结构算法与机器学习"></a>数据结构算法与机器学习</h1><p>最近研究了很多机器学习相关的概念和算法，发现其的核心理念就是使用计算机模拟人类的学习方法，来处理数据。才发现其实数据结构与算法是机器学习的基础。<br>二者都是使用算法来处理数据，得到一些结果。<br>区别在于，机器学习的数据非此处的结构化数据，往往需要进行预处理和特征抽取；算法也是复杂得多的模型和训练算法，目的是为了进行预测。<br>总体来说，计算机的数据结构与算法，是机器学习的基础。</p>
<h1 id="数据结构与算法的架构"><a href="#数据结构与算法的架构" class="headerlink" title="数据结构与算法的架构"></a>数据结构与算法的架构</h1><p>本书将数据结构与算法分为八大思想，数据结构，数据查找和排序四大部分。其中，八大思想讲述了日常算法中常用的八种思想；数据结构体现了数据在计算机中的组织形式，包括物理形式和逻辑形式，给出了数据在计算机中存储和运算的基本方法；最后，查找和排序，是数据处理最常见的需求，也是最基本的算法。<br>组织形式如下：</p>
<ul>
<li>算法思想<ul>
<li>枚举</li>
<li>递归</li>
<li>递推</li>
<li>迭代</li>
<li>分治</li>
<li>贪心</li>
<li>试探</li>
<li>模拟</li>
</ul>
</li>
<li>数据结构<ul>
<li>基本结构<ul>
<li>线性表</li>
<li>队列</li>
<li>栈</li>
</ul>
</li>
<li>逻辑结构<ul>
<li>树<ul>
<li>二叉树</li>
<li>霍夫曼树</li>
</ul>
</li>
<li>图<ul>
<li>有向图</li>
<li>无向图</li>
<li>连通图</li>
<li>生成树</li>
<li>深度遍历</li>
<li>广度遍历</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>查找<ul>
<li>基于线性表的查找</li>
<li>基于树的查找</li>
</ul>
</li>
<li>排序(<a href="http://www.cricode.com/3212.html" target="_blank" rel="external">图文详解八大排序算法</a>)<ul>
<li>交换排序<ul>
<li>冒泡排序</li>
<li>快速排序</li>
</ul>
</li>
<li>插入排序<ul>
<li>希尔排序</li>
</ul>
</li>
<li>选择排序<ul>
<li>堆排序</li>
</ul>
</li>
<li>归并排序</li>
</ul>
</li>
</ul>
<p>相关思维导图如下图：<br><img src="https://git.oschina.net/breezedong/figure_bed/raw/master/data_algorithm.png" alt="image"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[UFLDL深度学习笔记]]></title>
      <url>http://yoursite.com/2016/05/25/DeepLearningnotes/</url>
      <content type="html"><![CDATA[<h1 id="深度学习学习笔记"><a href="#深度学习学习笔记" class="headerlink" title="深度学习学习笔记"></a>深度学习学习笔记</h1><blockquote>
<p>最近研究一篇论文，使用RNN（recurrence neural networks）识别二进制代码中函数的方法，考虑到相关的CNN，LSTM，t-SNE，LDA等名词和相关算法一直碰到，避无可避，遂整体的学习了一下DeepLearning相关的知识。</p>
</blockquote>
<h2 id="UFLDL教程"><a href="#UFLDL教程" class="headerlink" title="UFLDL教程"></a>UFLDL教程</h2><p>学习了<a href="http://ufldl.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B" target="_blank" rel="external">UFLDL教程</a>，理解深度学习相关的概念与思想，主要包括基本概念、数据处理以及深度学习三个部分，并画出思维导图如下：</p>
<ul>
<li>基本概念：主要包含参数，激励函数，代价函数等</li>
<li>相关数据处理：PCA，whitening，样本的均值与方差等</li>
<li>深度学习：深层神经网络，根据特性，有CNN,RNN等</li>
</ul>
<p><img src="https://git.oschina.net/breezedong/figure_bed/raw/master/ANN.png" alt="image"></p>
<p>从上面教程中，我学习到了神经网络的模型的基本概念、模型参数以及训练方法：<strong>通过初始化参数，进行前向传递，得到初始输出结果，根据初始输出与标准输出构造代价函数，通过梯度下降与反向传播求导的方法，调整参数，迭代直至参数最优</strong><br>教程主要侧重神经网络的数学求解。</p>
<h2 id="zouxy09深度学习笔记整理系列博客"><a href="#zouxy09深度学习笔记整理系列博客" class="headerlink" title="zouxy09深度学习笔记整理系列博客"></a>zouxy09深度学习笔记整理系列博客</h2><p>而后，学习<a href="http://blog.csdn.net/zouxy09/article/details/8775488" target="_blank" rel="external">zouxy09</a>深度学习笔记整理系列博客，从物理意义上去理解深度学习。</p>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>机器学习的目的就是使计算机模拟人类的学习方式，获得知识与技能，解决问题。<br>机器学习在很多领域都有着应用：</p>
<ul>
<li>image: computer vision</li>
<li>voice: speech recognition</li>
<li>text: natural language process</li>
</ul>
<p>他们当前都有着很类似的处理过程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">low-level-sensing--&gt;pre-processing</span><br><span class="line"></span><br><span class="line">pre-processing--&gt;feature-extract</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">feature-extract--&gt;feature-selection</span><br><span class="line"></span><br><span class="line">feature-selection--&gt;inference-prediction-recognition</span><br></pre></td></tr></table></figure>
<p>即：通过传感器收集数据，经过数据预处理，得到可输入数据，经过特征工程，对数据特征进行抽取，选择，得到表征特点的特征，输入系统，算法进行推理，预测和识别等任务。</p>
<p>当前的机器学习，虽然在监督学习方法上，取得了很好的成果，但学习前往往需要在数据预处理、特征抽取和特征选择三个步骤耗费大量的人工精力。人工特征工程，是一件非常耗时耗力、启发式（需要专业的知识）的方法，选取的结果在一定程度上依赖经验和运气。</p>
<p>在此背景下，神经网络结合人脑视觉原理，将神经网络与层层抽象，形成深层神经网络；加上卷积等局部连接的方法，使得深层神经网络的参数训练得以实现。深度学习最大的优势在于，它可以让机器来学习特征，从而解决前面的特征工程问题。<strong>深度学习亦可称为unsupervised feature learning</strong>.</p>
<h3 id="特征表示"><a href="#特征表示" class="headerlink" title="特征表示"></a>特征表示</h3><p>1995 年前后，Bruno Olshausen和 David Field 两位学者做了一个实验。<br>收集很多黑白风景照，抽取了400张16*16的碎片：S[i]i=0,…,399，然后随意的抽取了一张碎片T。<br>通过叠加的方法，抽取一组S[i]中碎片拟合T。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(a[k]*S[k]) -&gt; T</span><br></pre></td></tr></table></figure>
<p>其中，a[k]为叠加权重。<br>为解决这个问题，Bruno Olshausen和 David Field 发明了一个算法，稀疏编码（Sparse Coding）。稀疏编码是一个重复迭代的过程，每次迭代分两步：</p>
<ol>
<li><p>选择一组 S[k]，然后调整 a[k]，使得Sum_k (a[k] * S[k]) 最接近 T。</p>
</li>
<li><p>固定住 a[k]，在 400个碎片中，选择其它更合适的碎片S’[k]，替代原先的 S[k]，使得Sum_k (a[k] * S’[k]) 最接近 T。</p>
</li>
</ol>
<p>经过几次迭代后，最佳的 S[k] 组合，被遴选出来了。令人惊奇的是，被选中的 S[k]，基本上都是照片上不同物体的边缘线，这些线段形状相似，区别在于方向。<br><strong>也就是说，复杂图形，往往由一些基本结构组成<br>。</strong><br>如下图所示：<img src="https://git.oschina.net/breezedong/figure_bed/raw/master/dl-feature-combine.jpg" alt="image"></p>
<p> 小块的图形可以由基本edge构成，更结构化，更复杂的，具有概念性的图形如何表示呢？这就需要更高层次的特征表示，比如V2，V4。因此V1看像素级是像素级。V2看V1是像素级，这个是层次递进的，高层表达由底层表达的组合而成。专业点说就是基basis。V1取提出的basis是边缘，然后V2层是V1层这些basis的组合，这时候V2区得到的又是高一层的basis。即上一层的basis组合的结果，上上层又是上一层的组合basis……（所以有大牛说Deep learning就是“搞基”，因为难听，所以美其名曰Deep learning或者Unsupervised Feature Learning）</p>
<p>从文本来说，一个doc表示什么意思？我们描述一件事情，用什么来表示比较合适？用一个一个字嘛，我看不是，字就是像素级别了，起码应该是term，换句话说每个doc都由term构成，但这样表示概念的能力就够了嘛，可能也不够，需要再上一步，达到topic级，有了topic，再到doc就合理。但每个层次的数量差距很大，比如doc表示的概念-&gt;topic（千-万量级）-&gt;term（10万量级）-&gt;word（百万量级）。</p>
<p>一个人在看一个doc的时候，眼睛看到的是word，由这些word在大脑里自动切词形成term，在按照概念组织的方式，先验的学习，得到topic，然后再进行高层次的learning。 </p>
<h3 id="浅层学习与深度学习"><a href="#浅层学习与深度学习" class="headerlink" title="浅层学习与深度学习"></a>浅层学习与深度学习</h3><h4 id="Shallow-Learning"><a href="#Shallow-Learning" class="headerlink" title="Shallow Learning"></a>Shallow Learning</h4><p>浅层学习是机器学习的第一次浪潮。</p>
<p>20世纪80年代末期，用于人工神经网络的反向传播算法（也叫Back Propagation算法或者BP算法）的发明，给机器学习带来了希望，掀起了基于统计模型的机器学习热潮。这个热潮一直持续到今天。人们发现，利用BP算法可以让一个人工神经网络模型从大量训练样本中学习统计规律，从而对未知事件做预测。这种基于统计的机器学习方法比起过去基于人工规则的系统，在很多方面显出优越性。这个时候的人工神经网络，虽也被称作多层感知机（Multi-layer Perceptron），但实际是种只含有一层隐层节点的浅层模型。</p>
<p>20世纪90年代，各种各样的浅层机器学习模型相继被提出，例如支撑向量机（SVM，Support Vector Machines）、 Boosting、最大熵方法（如LR，Logistic Regression）等。这些模型的结构基本上可以看成带有一层隐层节点（如SVM、Boosting），或没有隐层节点（如LR）。这些模型无论是在理论分析还是应用中都获得了巨大的成功。相比之下，由于理论分析的难度大，训练方法又需要很多经验和技巧，这个时期浅层人工神经网络反而相对沉寂。</p>
<h4 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h4><p>深度学习是机器学习的第二次浪潮。</p>
<p> 2006年，加拿大多伦多大学教授、机器学习领域的泰斗Geoffrey Hinton和他的学生RuslanSalakhutdinov在《科学》上发表了一篇文章，开启了深度学习在学术界和工业界的浪潮。这篇文章有两个主要观点：1）多隐层的人工神经网络具有优异的特征学习能力，学习得到的特征对数据有更本质的刻画，从而有利于可视化或分类；2）深度神经网络在训练上的难度，可以通过“逐层初始化”（layer-wise pre-training）来有效克服，在这篇文章中，逐层初始化是通过无监督学习实现的。</p>
<p>当前多数分类、回归等学习方法为浅层结构算法，其局限性在于有限样本和计算单元情况下对复杂函数的表示能力有限，针对复杂分类问题其泛化能力受到一定制约。深度学习可通过学习一种深层非线性网络结构，实现复杂函数逼近，表征输入数据分布式表示，并展现了强大的从少数样本集中学习数据集本质特征的能力。（多层的好处是可以用较少的参数表示复杂的函数）</p>
<p>深度学习的实质，是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。因此，“深度模型”是手段，“特征学习”是目的。区别于传统的浅层学习，深度学习的不同在于：1）强调了模型结构的深度，通常有5层、6层，甚至10多层的隐层节点；2）明确突出了特征学习的重要性，也就是说，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更加容易。与人工规则构造特征的方法相比，利用大数据来学习特征，更能够刻画数据的丰富内在信息。</p>
<h3 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><p>卷积神经网络讲解：<br><a href="http://yann.lecun.com/exdb/lenet/index.html" target="_blank" rel="external">zouxy09博客</a></p>
<p>经典案例：<br><a href="http://yann.lecun.com/exdb/lenet/index.html" target="_blank" rel="external">手写识别</a></p>
<h3 id="总结与展望"><a href="#总结与展望" class="headerlink" title="总结与展望"></a>总结与展望</h3><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>深度学习是将特征工程与分类预测任务结合，自动学习特征，由低层次特征向高层次特征不断抽象，形成多层次神经网络的模型方法。<br>其最主要特征在于：<strong>其深度的层次，丰富的参数赋予其强大的表达能力，能够拟合更复杂的函数与模型，特别是非线性函数，对大规模数据分析处理上较浅层算法有良好的效果。</strong></p>
<h4 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h4><p>深度学习作为当前监督学习算法中，在大规模数据背景下最优秀的算法，在computer vision/speech recognition/natural language process等方面有着很好的应用。</p>
<ol>
<li>从应用方面：</li>
</ol>
<ul>
<li>其在不同的应用场景下，学习框架的设计，是非常复杂的，需要更多的理论支撑和实际的测试。</li>
<li>深度学习参数众多，实际使用过程中，参数的设计与训练是难点。</li>
<li>怎样结合并行计算的优势，来构建深度学习。</li>
</ul>
<ol>
<li><p>从学习方法方面：<br>深度学习在监督学习方面应用做的很好，但在计算机模拟人类学习的需求下，非监督学习在人类学习方法中占主要比例。这也是深度学习的发展方向。</p>
</li>
<li><p>从实际使用方面：<br>据说hinton都说不清深度学习是怎么工作的，估计世界上很少有人能说出为什么它里面的物理意义吧。当前最好的办法就是，把dl当做黑箱子来用，基于经验和结果来调整参数。</p>
</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[深度学习轶事]]></title>
      <url>http://yoursite.com/2016/05/25/deeplearning%E8%BD%B6%E4%BA%8B/</url>
      <content type="html"><![CDATA[<p>最近在研究深度学习，在阅读文献过程中，也接触到不少名人轶事，个人认为非常有意思，对理解整个人工智能发展历程有不少帮助。</p>
<h2 id="Geoffrey-Hinton-amp-AI-revolution"><a href="#Geoffrey-Hinton-amp-AI-revolution" class="headerlink" title="Geoffrey Hinton &amp; AI revolution"></a>Geoffrey Hinton &amp; AI revolution</h2><blockquote>
<p>从1950年图灵提出图灵测试开始，人们对人工智能有了很高的期待。然而，半个多世纪过去，人工智能除了能用一些神经网络、支持向量机等浅层学习算法拟合一些线性模型和少数简单非线性模型外，远远没有达到图灵测试的要求，甚至有人讲机器学习称为伪科学。直到Geoffrey Hinton在2006年提出深度学习，这一能够模拟人类处理“抽象概念”的算法模型…</p>
</blockquote>
<p>图灵测试：<br>隔墙对话，让人分不出对方是机器还是人类。<br>人工智能发展半个多世纪，离图灵测试相距甚远，直到深度学习的出现。<br>其基于抽象概念的深层次网络，丰富的参数，能够拟合复杂的非线性函数与模型，对大规模数据具有良好的表达处理能力。<br>这里不得不提的人物： </p>
<ul>
<li>Geoffrey Hinton：神经网络鼻祖，深度学习发明者，曾任教Cambridge、CMU，目前任教University of Toronto</li>
<li>Yoshua Bengio：经历比较简单，McGill University 获得博士后，去 MIT 追随 Mike Jordan 做博士后。目前任教 University of Montreal。</li>
</ul>
<h2 id="Google-兵分两路"><a href="#Google-兵分两路" class="headerlink" title="Google 兵分两路"></a>Google 兵分两路</h2><p>Deep Learning引爆的这一波人工智能热潮，不仅在学术界，更在工业界产生不小的影响。相关的技术，在工业界犹如一把开山斧，等待着是各大公司一路披荆斩棘，动用资本和商业的强力手段，跑马圈地了。<br>Google作为全球从学术界转入工业界的翘楚与典范，自然不会错过这次机会。<br>Google兵分两路，左路以 Jeff Dean 和 Andrew Ng 为首，重点突破 Deep Learning等等算法和应用，右路军由 Amit Singhal 领军，目标是构建 Knowledge Graph 基础设施。</p>
<p>不得不提的大牛：</p>
<ul>
<li>Jeff Dean：  Google 诸位 Fellows 中，名列榜首，GFS 就是他的杰作。Andrew Ng 本科时，就读 CMU，后来去 MIT 追随 Mike Jordan。</li>
<li>Andrew Ng：Mike Jordan 在 MIT 人缘不好，后来愤然出走 UC Berkeley。Andrew Ng 毫不犹豫追随导师，也去了 Berkeley。拿到博士后，任教 Stanford，是 Stanford 新生代教授中的佼佼者，同时兼职 Google。</li>
<li>Amit Singhal：1996 年 Amit Singhal 从 Cornell University 拿到博士学位后，去 Bell Lab 工作，2000 年加盟 Google。据说他去 Google 面试时，对 Google 创始人 Sergey Brian 说，“Your engine is excellent, but let me rewirte it!”。Amit Singhal 目前任职 Google 高级副总裁，掌管 Google最核心的业务，搜索引擎。</li>
</ul>
]]></content>
    </entry>
    
  
  
</search>
